#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Mock AI API Server

Creates a local HTTP server that simulates AI model API responses.
Returns predefined random prompt data for frontend development and testing.

Usage:
    python mock_ai_api.py [--port PORT]
    Default port: 8000
"""

import json
import random
import argparse
from http.server import HTTPServer, BaseHTTPRequestHandler
from urllib.parse import urlparse, parse_qs
import time
import os

# ä»data.jsonæ–‡ä»¶ä¸­è¯»å–æç¤ºæ•°æ®
def load_prompts():
    script_dir = os.path.dirname(os.path.abspath(__file__))
    data_file = os.path.join(script_dir, 'data.json')
    try:
        with open(data_file, 'r', encoding='utf-8') as f:
            # ç›´æ¥åŠ è½½å·²ç»æ ¼å¼åŒ–å¥½çš„åµŒå¥—æ•°ç»„
            return json.load(f)
    except Exception as e:
        print(f'Failed to load prompts: {e}')
        return []

# åŠ è½½æç¤ºæ•°æ®
PROMPTS = load_prompts()
# åˆå§‹åŒ–æœªä½¿ç”¨çš„æç¤ºæ± å’Œå·²ä½¿ç”¨çš„æç¤ºæ± 
UNUSED_PROMPTS = list(range(len(PROMPTS)))
USED_PROMPTS = []

class AIAPIHandler(BaseHTTPRequestHandler):
    """å¤„ç†AI APIè¯·æ±‚çš„HTTPå¤„ç†å™¨"""
    
    def _set_headers(self, content_type="application/json"):
        """è®¾ç½®HTTPå“åº”å¤´ï¼ŒåŒ…æ‹¬CORSæ”¯æŒ"""
        self.send_response(200)
        self.send_header('Content-type', content_type)
        self.send_header('Access-Control-Allow-Origin', '*')
        self.send_header('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')
        self.send_header('Access-Control-Allow-Headers', 'Content-Type, Authorization, X-Requested-With')
        self.send_header('Access-Control-Allow-Credentials', 'true')
        self.send_header('Access-Control-Max-Age', '86400')
        self.end_headers()
    
    def do_OPTIONS(self):
        """å¤„ç†OPTIONSè¯·æ±‚ï¼Œæ”¯æŒCORSé¢„æ£€è¯·æ±‚"""
        self._set_headers()
        self.wfile.write(b'')

    def do_POST(self):
        global UNUSED_PROMPTS, USED_PROMPTS
        
        content_length = int(self.headers['Content-Length'])
        post_data = self.rfile.read(content_length)
        
        # ç”ŸæˆéšæœºIDå’Œæ—¶é—´æˆ³
        response_id = f"{random.randint(100000, 999999)}-{random.randint(1000, 9999)}-{random.randint(1000, 9999)}-{random.randint(1000, 9999)}-{random.randint(100000000000, 999999999999)}"
        created_timestamp = int(time.time())
        
        # ä»æœªä½¿ç”¨æ± ä¸­éšæœºé€‰æ‹©æç¤ºï¼Œå¦‚æœæœªä½¿ç”¨æ± ä¸ºç©ºåˆ™é‡ç½®
        selected_indices = []
        
        for _ in range(min(5, len(PROMPTS))):
            if not UNUSED_PROMPTS:
                print("âš ï¸ All prompts have been used once, resetting prompt pool")
                UNUSED_PROMPTS = USED_PROMPTS
                USED_PROMPTS = []
                
            # ä»æœªä½¿ç”¨æ± ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªç´¢å¼•
            random_index = random.randint(0, len(UNUSED_PROMPTS) - 1)
            prompt_index = UNUSED_PROMPTS.pop(random_index)
            USED_PROMPTS.append(prompt_index)
            selected_indices.append(prompt_index)
        
        # åªåœ¨è¯·æ±‚ç»“æŸæ—¶è¾“å‡ºä¸€æ¬¡ä½¿ç”¨æƒ…å†µ
        print(f"ğŸ“Š Used: {len(USED_PROMPTS)}/{len(PROMPTS)}")

        bilingual_prompts = [PROMPTS[i] for i in selected_indices]
        
        # æ„å»ºå®Œæ•´çš„DeepSeek APIå“åº”æ ¼å¼
        response = {
            "id": response_id,
            "object": "chat.completion",
            "created": created_timestamp,
            "model": "deepseek-chat",
            "choices": [
                {
                    "index": 0,
                    "message": {
                        "role": "assistant",
                        "content": f"```json\n{json.dumps(bilingual_prompts, ensure_ascii=False, indent=4)}\n```"
                    },
                    "logprobs": None,
                    "finish_reason": "stop"
                }
            ],
            "usage": {
                "prompt_tokens": random.randint(300, 350),
                "completion_tokens": random.randint(900, 1100),
                "total_tokens": random.randint(1200, 1400),
                "prompt_tokens_details": {"cached_tokens": 0},
                "prompt_cache_hit_tokens": 0,
                "prompt_cache_miss_tokens": random.randint(300, 350)
            },
            "system_fingerprint": f"fp_{random.randint(10000000, 99999999)}_{random.choice(['prod0225', 'prod0301', 'prod0315'])}"
        }
        
        # æ·»åŠ éšæœºå»¶è¿Ÿï¼ˆ1-5ç§’ï¼‰æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
        delay_time = random.uniform(1, 5)
        print(f"Simulated delay: {delay_time:.2f}s")
        time.sleep(delay_time)
        
        self._set_headers()
        self.wfile.write(json.dumps(response, ensure_ascii=False).encode())


if __name__ == '__main__':
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='Start mock AI API server')
    parser.add_argument('--port', type=int, default=8000, help='Server port (default: 8000)')
    args = parser.parse_args()

    # åˆ›å»ºæœåŠ¡å™¨å®ä¾‹
    server_address = ('', args.port)
    httpd = HTTPServer(server_address, AIAPIHandler)
    
    try:
        # è¾“å‡ºå¯åŠ¨ä¿¡æ¯
        print(f'ğŸš€ Server started at http://localhost:{args.port}')
        print('ğŸ“¡ Available endpoints:')
        print(f'â€¢ POST http://localhost:{args.port}/  Get random prompts (1-5s delay)')
        print('ğŸ“Š Current status: Total {0} prompts'.format(len(PROMPTS)))
        print('\nğŸ” Request example:')
        print(f'curl -X POST http://localhost:{args.port}/ -H "Content-Type: application/json" -d \'{{"model": "deepseek-chat"}}\'')
        print('\nğŸ›‘ Press Ctrl+C to stop the server')
        
        # å¯åŠ¨æœåŠ¡
        httpd.serve_forever()
    except KeyboardInterrupt:
        print('\nğŸ›‘ Server stopped')
    except OSError as e:
        if e.errno == 48:
            print(f'âŒ Port {args.port} is already in use, please use a different port')
        else:
            print(f'âŒ Failed to start: {str(e)}')